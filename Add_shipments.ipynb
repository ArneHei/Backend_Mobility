{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODE0LkyK0MO6W09v0mTIgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArneHei/Backend_Mobility/blob/main/Add_shipments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Test to see if code works\n",
        "\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Float, Boolean, Date, Time\n",
        "from sqlalchemy.orm import sessionmaker, declarative_base\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import nbformat\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "#\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSjHXYFSR8Tx",
        "outputId": "1884a55f-f7bc-4c2f-df88-7183a0f07b05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHDLE-N9ha-T"
      },
      "outputs": [],
      "source": [
        "#Create data set from Filepath\n",
        "\n",
        "\n",
        "# Define the base class for declarative models\n",
        "Base = declarative_base()\n",
        "\n",
        "class ShipmentDB(Base):\n",
        "    __tablename__ = 'shipments'\n",
        "\n",
        "    Shipment_ID = Column(String, primary_key=True)\n",
        "    Transport = Column(String)\n",
        "    Department = Column(String)\n",
        "    Pickup_time = Column(String)\n",
        "    Pickup_date = Column(Date)\n",
        "    Delivery_time = Column(String)\n",
        "    Delivery_date = Column(Date)\n",
        "    Collection_Name = Column(String)\n",
        "    Collection_City = Column(String)\n",
        "    Collection_Address = Column(String)\n",
        "    Collection_Postal_Code = Column(String)\n",
        "    Delivery_Name = Column(String)\n",
        "    Delivery_City = Column(String)\n",
        "    Delivery_Address = Column(String)\n",
        "    Delivery_Postal_Code = Column(String)\n",
        "    Weight = Column(Float)\n",
        "    Volume = Column(Float)\n",
        "    Ldm = Column(Float)\n",
        "    Content = Column(String)\n",
        "    Units = Column(Integer)\n",
        "    Unit_type = Column(String)\n",
        "    Hazardous = Column(Boolean)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"<Shipment(Shipment_ID='{self.Shipment_ID}', Transport='{self.Transport}', Department='{self.Department}')>\"\n",
        "\n",
        "#process new files to create shipments and add to DB\n",
        "def process_shipment_files(file_paths: list):\n",
        "    \"\"\"Loads, processes, and filters shipment data from a list of Excel files.\n",
        "    Returns a list of Shipment objects.\"\"\"\n",
        "    all_dfs = []\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            df = pd.read_excel(file_path, header=0)\n",
        "            all_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {e}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "    if not all_dfs:\n",
        "        print(\"No dataframes were loaded.\")\n",
        "        return []\n",
        "\n",
        "    concatenated_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    # Step 1: Create a working copy to avoid SettingWithCopyWarning\n",
        "    df_modified = concatenated_df.copy()\n",
        "\n",
        "    # Step 2: Initialize new columns with pd.NA\n",
        "    df_modified['Pick up time'] = pd.NA\n",
        "    df_modified['Delivery time'] = pd.NA\n",
        "\n",
        "    # Step 3 & 4: Populate 'Delivery time' and 'Pick up time' based on 'Type'\n",
        "    df_modified.loc[df_modified['Type'] == 'D', 'Delivery time'] = df_modified['Expected Handling']\n",
        "    df_modified.loc[df_modified['Type'] == 'P', 'Pick up time'] = df_modified['Expected Handling']\n",
        "\n",
        "    # Step 5: Define aggregation dictionary\n",
        "    agg_dict = {\n",
        "        col: (lambda x: str(x.dropna().iloc[0]) if not x.dropna().empty else pd.NA)\n",
        "        if col in ['Delivery time', 'Pick up time']\n",
        "        else 'first'\n",
        "        for col in df_modified.columns if col != 'Shipment'\n",
        "    }\n",
        "\n",
        "    # Step 6: Group by 'Shipment' and apply aggregation\n",
        "    df_modified = df_modified.groupby('Shipment', as_index=False).agg(agg_dict)\n",
        "\n",
        "    # Filter for completed shipments (those with both 'Pick up time' and 'Delivery time')\n",
        "    df_completed_shipments = df_modified[df_modified['Pick up time'].notna() & df_modified['Delivery time'].notna()]\n",
        "\n",
        "    print(\"df_modified created and consolidated within the function.\")\n",
        "\n",
        "    # --- Start of new logic to create Shipment objects ---\n",
        "    shipment_objects = []\n",
        "\n",
        "    # Helper function to parse the custom datetime string 'YYYY-MM-DD HH:MM-HH:MM'\n",
        "    def parse_custom_datetime_string(dt_value):\n",
        "        if pd.notna(dt_value) and isinstance(dt_value, str):\n",
        "            try:\n",
        "                # Expected format: YYYY-MM-DD HH:MM-HH:MM\n",
        "                parts = dt_value.split(' ')\n",
        "                if len(parts) == 2:\n",
        "                    date_part = parts[0] # YYYY-MM-DD\n",
        "                    time_range_part = parts[1] # HH:MM-HH:MM\n",
        "\n",
        "                    dt_obj_date = pd.to_datetime(date_part, utc=True)\n",
        "\n",
        "                    return time_range_part, dt_obj_date.strftime('%Y-%m-%d')\n",
        "                else:\n",
        "                    # If not the specific format, try general parsing as fallback\n",
        "                    try:\n",
        "                        dt_obj = pd.to_datetime(dt_value, utc=True)\n",
        "                        return dt_obj.strftime('%H:%M:%S'), dt_obj.strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                        return None, None # Could not parse\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not parse custom datetime string '{dt_value}': {e}\")\n",
        "                return None, None\n",
        "        elif pd.notna(dt_value) and isinstance(dt_value, pd.Timestamp):\n",
        "            return dt_value.strftime('%H:%M:%S'), dt_value.strftime('%Y-%m-%d')\n",
        "        return None, None # Handle NaN or other non-string/non-timestamp values\n",
        "\n",
        "    for index, row in df_completed_shipments.iterrows():\n",
        "        try:\n",
        "            # a. Call the parse_custom_datetime_string helper function\n",
        "            pickup_time_str, pickup_date_str = parse_custom_datetime_string(row['Pick up time'])\n",
        "            # b. Similarly, call parse_custom_datetime_string for delivery\n",
        "            delivery_time_str, delivery_date_str = parse_custom_datetime_string(row['Delivery time'])\n",
        "\n",
        "            # c. Derive Department value\n",
        "            current_shipment_id = row['Shipment']\n",
        "            department_value = None\n",
        "            # Use the original concatenated_df for department derivation\n",
        "            p_type_entry = concatenated_df[(concatenated_df['Shipment'] == current_shipment_id) & (concatenated_df['Type'] == 'P')]\n",
        "            if not p_type_entry.empty:\n",
        "                derived_transport_id = p_type_entry.iloc[0]['Transport']\n",
        "                if isinstance(derived_transport_id, str) and len(derived_transport_id) >= 3:\n",
        "                    department_value = derived_transport_id[:3] + 'ST'\n",
        "\n",
        "            # d. Convert Hazardous string to boolean\n",
        "            hazardous_value = None\n",
        "            if isinstance(row['Haz'], str):\n",
        "                hazardous_value = True if row['Haz'].lower() == 'yes' else False\n",
        "            elif isinstance(row['Haz'], bool):\n",
        "                hazardous_value = row['Haz']\n",
        "\n",
        "            # f. Create a Shipment object for each row\n",
        "            shipment = Shipment(\n",
        "                Shipment_ID=row['Shipment'],\n",
        "                Transport=None, # As per instruction\n",
        "                Department=department_value,\n",
        "                Pickup_time=pickup_time_str,\n",
        "                Pickup_date=pickup_date_str,\n",
        "                Delivery_time=delivery_time_str,\n",
        "                Delivery_date=delivery_date_str,\n",
        "                Collection_Name=row['Collection Name'],\n",
        "                Collection_City=row['Collection City'],\n",
        "                Collection_Address=row['Collection Address'],\n",
        "                Collection_Postal_Code=row['Collection Postal Code'],\n",
        "                Delivery_Name=row['Delivery Name'],\n",
        "                Delivery_City=row['Delivery City'],\n",
        "                Delivery_Address=row['Delivery Address'],\n",
        "                Delivery_Postal_Code=row['Delivery Postal Code'],\n",
        "                Weight=row['Total Weight'],\n",
        "                Volume=row['Total Volume'],\n",
        "                Ldm=row['Ldm'],\n",
        "                Content=row['Content'],\n",
        "                Units= int(row['Expected Items']),\n",
        "                Unit_type=row['Items of Type'],\n",
        "                Hazardous=hazardous_value\n",
        "            )\n",
        "            # g. Append the newly created Shipment object to the shipment_objects list.\n",
        "            shipment_objects.append(shipment)\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating Shipment object for row {index} (Shipment ID: {row['Shipment']}): {e}\")\n",
        "\n",
        "    print(f\"Successfully created {len(shipment_objects)} Shipment objects.\")\n",
        "    # --- End of new logic ---\n",
        "    engine = create_engine('sqlite:////content/drive/MyDrive/Driver app/shipments.db')\n",
        "\n",
        "    # Create tables if they don't exist\n",
        "    Base.metadata.create_all(engine)\n",
        "\n",
        "    Session = sessionmaker(bind=engine)\n",
        "    session = Session()\n",
        "\n",
        "    for shipment in shipment_objects:\n",
        "        try:\n",
        "            # Check if a shipment with the same Shipment_ID already exists\n",
        "            existing_shipment = session.query(ShipmentDB).filter_by(Shipment_ID=shipment.Shipment_ID).first()\n",
        "\n",
        "            if existing_shipment is None:\n",
        "                # Convert date strings to datetime.date objects\n",
        "                pickup_date_obj = None\n",
        "                if shipment.Pickup_date:\n",
        "                    try:\n",
        "                        pickup_date_obj = datetime.datetime.strptime(shipment.Pickup_date, '%Y-%m-%d').date()\n",
        "                    except ValueError:\n",
        "                        print(f\"Warning: Could not parse Pickup_date '{shipment.Pickup_date}' for shipment {shipment.Shipment_ID}\")\n",
        "\n",
        "                delivery_date_obj = None\n",
        "                if shipment.Delivery_date:\n",
        "                    try:\n",
        "                        delivery_date_obj = datetime.datetime.strptime(shipment.Delivery_date, '%Y-%m-%d').date()\n",
        "                    except ValueError:\n",
        "                        print(f\"Warning: Could not parse Delivery_date '{shipment.Delivery_date}' for shipment {shipment.Shipment_ID}\")\n",
        "\n",
        "\n",
        "                db_shipment = ShipmentDB(\n",
        "                    Shipment_ID=shipment.Shipment_ID,\n",
        "                    Transport=shipment.Transport,\n",
        "                    Department=shipment.Department,\n",
        "                    Pickup_time=shipment.Pickup_time,\n",
        "                    Pickup_date=pickup_date_obj,\n",
        "                    Delivery_time=shipment.Delivery_time,\n",
        "                    Delivery_date=delivery_date_obj,\n",
        "                    Collection_Name=shipment.Collection_Name,\n",
        "                    Collection_City=shipment.Collection_City,\n",
        "                    Collection_Address=shipment.Collection_Address,\n",
        "                    Collection_Postal_Code=shipment.Collection_Postal_Code,\n",
        "                    Delivery_Name=shipment.Delivery_Name,\n",
        "                    Delivery_City=shipment.Delivery_City,\n",
        "                    Delivery_Address=shipment.Delivery_Address,\n",
        "                    Delivery_Postal_Code=shipment.Delivery_Postal_Code,\n",
        "                    Weight=shipment.Weight,\n",
        "                    Volume=shipment.Volume,\n",
        "                    Ldm=shipment.Ldm,\n",
        "                    Content=shipment.Content,\n",
        "                    Units=shipment.Units,\n",
        "                    Unit_type=shipment.Unit_type,\n",
        "                    Hazardous=shipment.Hazardous\n",
        "                )\n",
        "                session.add(db_shipment)\n",
        "                print(f\"Added shipment with Shipment ID: {shipment.Shipment_ID}\")\n",
        "            else:\n",
        "                print(f\"Shipment with Shipment ID: {shipment.Shipment_ID} already exists. Skipping.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding shipment to session: {e}\")\n",
        "\n",
        "    try:\n",
        "        session.commit()\n",
        "        print(f\"Successfully committed changes to the database.\")\n",
        "    except Exception as e:\n",
        "        session.rollback()\n",
        "        print(f\"Error committing shipments to database: {e}\")\n",
        "    finally:\n",
        "        session.close()\n",
        "\n",
        "    return shipment_objects"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Code to run to test\n",
        "\n",
        "#DMP files for generating shipments.\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Data handling/SEST0408.xlsx\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Data handling/SEST0508.xlsx\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Data handling/SEST0608.xlsx\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Data handling/SEST0708.xlsx\",\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Data handling/SEST0808.xlsx\"\n",
        "]\n",
        "\n",
        "#Calls the function and uses the selected data files to generate shipments from them\n",
        "shipment_objects = process_shipment_files(file_paths)\n",
        "\n",
        "print(f\"Total shipment objects created: {len(shipment_objects)}\")\n",
        "\n",
        "\n",
        "# Displaying the first and 10th created shipment object for verification\n",
        "if shipment_objects:\n",
        "    print(\"\\nDetails of the first created Shipment object:\")\n",
        "    first_shipment = shipment_objects[0]\n",
        "    print(f\"Shipment_ID: {first_shipment.Shipment_ID}\")\n",
        "    print(f\"Transport: {first_shipment.Transport}\")\n",
        "    print(f\"Department: {first_shipment.Department}\")\n",
        "    print(f\"Pickup_time: {first_shipment.Pickup_time}\")\n",
        "    print(f\"Pickup_date: {first_shipment.Pickup_date}\")\n",
        "    print(f\"Delivery_time: {first_shipment.Delivery_time}\")\n",
        "    print(f\"Delivery_date: {first_shipment.Delivery_date}\")\n",
        "    print(f\"Collection_Name: {first_shipment.Collection_Name}\")\n",
        "    print(f\"Units: {first_shipment.Units} {first_shipment.Unit_type} of {first_shipment.Content}\")\n",
        "    print(\"\\n\\nDetails of the 10th created Shipment object:\")\n",
        "\n",
        "    first_shipment = shipment_objects[9]\n",
        "    print(f\"Shipment_ID: {first_shipment.Shipment_ID}\")\n",
        "    print(f\"Transport: {first_shipment.Transport}\")\n",
        "    print(f\"Department: {first_shipment.Department}\")\n",
        "    print(f\"Pickup_time: {first_shipment.Pickup_time}\")\n",
        "    print(f\"Pickup_date: {first_shipment.Pickup_date}\")\n",
        "    print(f\"Delivery_time: {first_shipment.Delivery_time}\")\n",
        "    print(f\"Delivery_date: {first_shipment.Delivery_date}\")\n",
        "    print(f\"Collection_Name: {first_shipment.Collection_Name}\")\n",
        "    print(f\"Units: {first_shipment.Units} {first_shipment.Unit_type} of {first_shipment.Content}\")\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "OCK-QQ-TS2ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBb3qckvOO4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}